\documentclass[12pt,letterpaper]{article}
% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[spanish]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=1cm,right=1cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{mathtools} 
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb,tikz}
\usepackage{amsfonts}
\usepackage{wrapfig}
\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corolario}[theorem]
\newtheorem{lemma}{Lema}[section]
\usepackage{etoolbox}
\usepackage{graphicx}
\usepackage{upgreek}
\usepackage{float}
\newcommand{\bigslant}[2]{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}
\usepackage{xcolor}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Estadística matemática}
\author{Wilfredo Gallegos}

\begin{document}
\maketitle

\textbf{Jueves 6 de julio}
\section{Contenido}
\section*{5.1}
\begin{definition}
	Sean $Y_1$ y $Y_2$ variables aleatorias discretas. La función de probabilidad conjunta para $Y_1$ y $Y_2$ es P$(y_1,y_2)=P(Y_1=y_1)$ $-\inf < y2<\inf$)
\end{definition}

\newpage
\textbf{martes 11 de julio}

\begin{definition}
	Si $Y_1$ y $Y_2$ son variables aleatorias discretas conjuntas con funcion de probabilidad conjunta $P(y_1,y_2)(P[Y_1=y_1]\cap [Y_2=y_2])$ y función marginal $P_1(y_1)(P[Y_1=y_1])$ y $P_2(y_2)(P[Y_2=y_2])$

\[\Rightarrow p(y_1|y_2) = P([Y_1=y_1]|[Y_1=y_1])=\frac{P([Y_1=y_1]\cap [Y_2=y_2])}{P([Y_2=y_2]}=\frac{P(y_1,y_2)}{P_2(y_2)},\ \ \ \textit{Siempre que } P_2(y_2)>0\]
\end{definition}

\textbf{Nota: } 
\[p(y_2|y_1)=\frac{P(y_1,y_2)}{P_1(y_1)}\geq 0\ y\ \sum p(y_1|y_1)=1\]

\textbf{5.7 ej. 5.5}

Encontrar la distrubución condicional de $Y_1$ dado $Y_2=1$
\[
\begin{array}{rl}
	Y_1:& \textit{\# de republicanos en el comite de 2 personas}\\
	Y_2:& \textit{\# de demócratas en el comite de 2 personas}\\
	p(Y_2=0|Y_2=1)=&\frac{{3 \choose 0}{2 \choose 1}{1 \choose 1}}{{6 \choose 2}}\left/\frac{{2 \choose 1}{4 \choose 1}}{{6 \choose 2}}\right.=\frac{2/15}{8/15}=\frac{1}{4}\\
	p(Y_2=1|Y_2=1)=&\frac{{3 \choose 1}{2 \choose 1}{1 \choose 0}}{{6 \choose 2}}\left/\frac{{2 \choose 1}{4 \choose 1}}{{6 \choose 2}}\right.=\frac{6/15}{8/15}=\frac{3}{4}
\end{array}
\]
\textbf{5.6}
\begin{definition}
	Si $Y_1$ y $Y_2$ son variales aleatorias continuas con función densidad conjunta $f(y_1,y_2)\Rightarrow $ la función de distribución acumulada condicional de $Y_1$, dado $Y_2=y_2$ es $F(y_1|y_2)=P(Y_1\leq y_1|Y_2=y_2)$
\end{definition}
\textbf{5.7}
\begin{definition}
	Sean $Y_1$ y $Y_2$ son variales aleatorias contunuas con funsion densidad conjunta $f(y_1,y_2)$ y densidades marginales $f_1(y_1)$ y $f_2(y_2)$. Para cualquier $y_2$ tal que $f_2(y_2)>0$, la densidad condiciona de $Y_1$, dado $Y_1=Y_2$ es 
	\[f(y_1|y_2)=\frac{f(y_1,y_2)}{f_2(y_2)}\]
y para cualquier $y_1\ni f_1(y_1)>0$, la densidad condicional de $Y_2$ dada $Y_1=y_1$ es 
\[f(y_2|y_1)=\frac{f(y_1,y_2)}{f_1(y_1)}\]
\end{definition}
\textbf{5.8 ej.}
\[
\begin{array}{rl}
	Y_2:& \textit{existencia de bebidas al inicio de un dia determinado}\\
	Y_1:& \textit{despacho durante el dia}\\
	& Y_1\leq Y_2\\
	f(y_1,y_2)=& \left\{
	\begin{array}{rl}
		1/2,&\ 0\leq y_1\leq y_2 \leq 2\\
		0,&\ \textit{en caso contrario}
	\end{array}
	\right.
\end{array}
\]
Encontrar la densidad condicional de $Y_1$ dad o$Y_2=y_2$ y calcular la probabilidad de que se venda menos o igual a 1/2 galón, dado que la maquina contiene 1.5 galones al empezar el dia.

\textbf{Sol: }

\[f_2(y_2)=\left\{
\begin{array}{ccr}
	\int^{\infty}_{-\infty} f(y_1,y_2)dy_1=\int^{y_2}_0\frac{1}{2}dy_1=\left.\frac{1}{2}y_1\right|^{y_2}_0=\frac{1}{2}y_2&,& 0\leq y_2\leq 2\\
	0&,& \textit{Cualquier otro caso}
\end{array}
\right.
\]
\begin{center}
\includegraphics[scale=.1]{../imagenes/imagen 1.jpeg} 
\end{center}
%------------------------------------------


Note que $f_2(y_2)>0$ en $0<y_1\leq 2$

$f(y_1|y_2)=\frac{f(y_1,y_2)}{f_2(y_2)}\frac{1/2}{1/2y_2}=\frac{1}{y_2}, 0<y_1\leq y_2 \leq 2$

Además, $f(y_1|y_2)$ es indefinida si $y_2\leq0$ 0 $y_2>2$

\textbf{5.8 ej.}

\[
\begin{array}{rl}
	P(Y_1\leq 1/2|Y_2 =1.5)=& \int^{1/2}_{-\infty} f(y_1|y_2=1.5)dy_1\\
	=& \int^{1/2}_{-\infty}\frac{1}{1.5}dy_1=\left.\frac{1}{1.5}y1\right|^{1/2}_0=\frac{1/2}{1.5}=\frac{1}{3}
\end{array}
\]
\[P(X\in A,Y\in B)=P(X\in A)P(Y\in B)\]
\textbf{5.7 Varaibles aleatorias independientes}

\textbf{5.8}
\begin{definition}
	Sean $Y_1$ con una función distribución acumulada $F_1(y_1)$ y $Y_2$ con función de distribución acumulada $F_1(y_1)$ y $F(y_1,y_2)$ es la función de distribución acumulada conjunta de $Y_1$ y $Y_2$, entonces $Y_1$ y $Y_2$ son independientes ssi $F(y_1,y_2)$=$F_1(y_1)F_2(y_2) \forall (y_1,y_2)\in \mathbb{R}^2$
Si $Y_1$ y $Y_2$ no son independientes son dependientes
\end{definition}

\begin{theorem}
	Dado una variable aleatoria $X\Rightarrow P([X=a])=\lim\limits_{n\to 0} P([a-n<x\leq a])$
\end{theorem}
\begin{proof}
	Sea $a\in\mathbb{R}$\\
	Como $\lim\limits_{n\to 0} a-n=a\left( \lim\limits_{n\to \infty} a-\frac{1}{h}\right)=a$
	\begin{center}
\includegraphics[scale=.5]{../imagenes/imagen 2.jpeg.jpg} 
\end{center}
Tomese una sucesión
\[\underset{a-1}{t_1}<\underset{a-\frac{1}{2}}{t_2}<...<\underset{a-\frac{1}{n}}{t_n}<a\]
tal que $\lim\limits_{n\to \infty}t_n=0$ y $A_n=[t_n<t\leq a]$
\[
\begin{array}{rl}
	A_1=& [a-1<t\leq a]\\
	A_2=& [a-1/2<t\leq a], A_2\subseteq A_1\\
	.\\
	.\\
	.\\
	A_n=& [a-1/n<t\leq a], A_n\subseteq A_{n-1}
	
\end{array}
\]
Luego
\[
\begin{array}{rl}
	\lim\limits_{n\to 0} P([a-n<x\leq a])=& \lim\limits_{n\to \infty} P([t_n<x\leq a])\\
	=& \lim\limits_{n\to \infty} P([x\leq a])- P([x\leq t_n])=P([x\leq a])-\underbrace{\lim\limits_{n\to \infty} P([X\leq t_n])}_{P([X < a])}\\
	=& P([X\leq a])-P([X < a])= P([X=a])
\end{array}
\]
\end{proof}
Por otro lado:
\[
\begin{array}{rl}
	C_1=& [x\leq t_1]\\
	C_2=& [x\leq t_2], C_1\subseteq C_2\\
	.\\
	.\\
	.\\
	C_n=& [x\leq t_n], C_{n-1}\subseteq C_n\\
	\\
	\lim\limits_{n\to \infty} [x\leq t_n]=& \bigcup^{\infty}_{i=1}[x\leq t_i]=[x<a]
\end{array}
\]
Luego
\[
\begin{array}{rl}
	B_1=& [x\leq t_1]\\
	B_2=& [x\leq t_2]\smallsetminus [x\leq t_1]\\
	.\\
	.\\
	.\\
	B_n=& [x\leq t_n]\smallsetminus [x\leq t_{n-1}]
\end{array}
\]
Notese que $B_i\cap B_j=\emptyset$ para $i\neq j$ y $\cup^n_{i=1}B_i=\cup^n_{i=1}[x\leq t_{i-1}]$\\*
entonces 
\[
\begin{array}{rl}
	P\left(\cup^{n}_{i=1}B_i\right)=&\sum^{n}_{i=1}P(B_i)\\
	\lim\limits_{n\to \infty} \sum^{n}_{i=1}P(B_i)=& \lim\limits_{n\to \infty}\sum^{n}_{i=2}P([x\leq t_i]\smallsetminus [x\leq t_{i-1}])+P([x\leq t_i])\\
	=& \sum^{n}_{i=2}\left[P([x\leq t_i])-P([x\leq t_{i-1}])\right]+P([x\leq t_i])\\
	=& \lim\limits_{n\to \infty} P([x\leq t_n])
\end{array}
\]

\begin{theorem}
\hfill
	\begin{enumerate}
		\item Si $Y_1$ y $Y_2$ son variables aleatorias discretas con función de probabilidad conjunta $P[y_1,y_2]$ y funciones marginales $P_1(y_1)$ y $P_2(y_2)$, entonces $Y_1$ y $Y_2$ son independientes ssi $P(y_1,y_2)=P_1(y_1)P_2(y_2),\forall y_1,y_2\in \mathbb{R}$
		\item Si $Y_1$ y $Y_2$ son variables aleatorias continuas con función densidad conjunta $f(y_1,y_2)$ y funciones densidades marginales $P_1(y_1)$ y $P_2(y_2)$, entonces $Y_1$ y $Y_2$ son independientes ssi $f(y_1,y_2)=f(y_1)f(y_2),\forall y_1,y_2\in \mathbb{R}$
	\end{enumerate}
\end{theorem}
\newpage
\textbf{martes 18 de julio}

\textbf{\textcolor{red}{Ej.}}

Sea X y Y variables aleatorias contincuas con funci'on densidad 
\[
f(x,y)=
\begin{cases}
	6e^{-2x}e^{-3y},& 0<x,y<\infty \\
	0,& \mathrm{\textit{En cualquier otro caso}}
\end{cases}\]
¿X y Y son variables aleatorias independientes?
\[I(x,y)=\left\{
\begin{array}{rl}
	1,& 0<x,y<\infty\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\[I(x)=\left\{
\begin{array}{rl}
	1,& 0<x<\infty\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\[
\begin{array}{rl}
	f(x,y)=&6e^{-2x}e^{-3y}\cdot I(x,y)=(2e^{-2x}\cdot I(x))\cdot (3e^{-3y}\cdot I(y))=\\
	\\
	=&f_x(x)f_y(y),\ \forall x,y\in \mathbb{R}
\end{array}
\]
Por el teorema 5.8, X y Y son variables aleatorias independientes.

\textbf{\textcolor{red}{Ej.}}

Sea X y Y variables aleatorias con funci'on densidad
\[f(x,y)=\left\{
\begin{array}{rl}
	24xy,& 0<x,y<1; 0<x+y<1\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\begin{center}
	\includegraphics[scale=.1]{../imagenes/imagen 3.jpeg} 
\end{center}
Claramente no se puede factorizar en 2 partes que de x y otro que depende de y. Por lo tanto, X y Y son variables aleatorias dependientes.

\textbf{5.9 Teorema}

Sean $Y_1$ y $Y_2$ variables aleatorias independientes y sean $g(Y_1)$ y $h(Y_2)$ funciones solo de $Y_1$ y $Y_2$. Entonces $E(g(Y_1)\cdot h(Y_2))=E(g(Y_1))\cdot E(h(Y_2))$ siempre que existan los valores esperados.

\textbf{\textcolor{red}{Ej.}}

En el ej. 5.19
\[
\begin{array}{rl}
	Y_2:& \textit{Proporci'on de impurezas en la muestra}\\
	Y_1:& \textit{dProporci'on de impurezas de tipo I entre todas las impurezas encontradas}\\
\end{array}
\]
\[f(y_1,y_2)=\left\{
\begin{array}{rl}
	2(1-y_1),0<y_1,y_2<1&\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
Encontrar $E(y_1,y_2)=E(y_1)\cdot E(y_2)$ si $Y_1$ y $Y_2$ son independientes.
\[
\begin{array}{rlr}
	E(y_1,y_2)=& \int^1_0 \int^1_0 \underbrace{y_1\cdot y_2}_{funciones}\cdot \underbrace{2(1-y_1)}_{\parbox{3.5em}{\footnotesize densidad conjunta}}dy_2dy_1 \\ \\
	=& 2\int^1_0y_1(1-y_1)\left.\frac{y_2^2}{2}\right|^1_0dy_1\\ \\
	=& 2\int^1_0y_1(1-y_1)\left(\frac{1}{2}\right)dy_1\\ \\
	=& 2\int^1_0 \frac{y_1}{2}-\frac{y_1^2}{2}dy_1=\left.\left[\frac{y_1^2}{4}-\frac{y_1^2}{6}\right]\cdot 2\right|^1_0=\\ \\
	=& 2\left(\frac{1}{4}-\frac{1}{6}\right)=\frac{1}{6}
\end{array}
\]
\par\noindent\rule{\textwidth}{0.5pt}
\textbf{Marginales}
\[f(y_1)=\left\{
\begin{array}{rl}
	\int^1_0 2(1-y_1)dy_2=2(1-y_1),&0\leq y_1 \leq 1\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\[f(y?2)=\left\{
\begin{array}{rl}
	\int^1_0 2(1-y_1)dy_1=\left.\vphantom{\frac{0}{0}} 2y_1-y_1^2\right|^1_0=1,& 0\leq y_2\leq 1\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\textbf{Valores ESperados}

\[
\begin{array}{rl}
	E(Y_1)=&\int^1_0y_1 (2)(1-y_1)dy_1=\int^1_0 2y_1-2y_1^2dy_1=y_!^2-\left.\frac{2}{3}y_1^3\right|^1_0=1-\frac{2}{3}=\frac{1}{3}\\
	E(Y_2)=& \int^1_0 y_2(1)dy_2=\left.\frac{y_2^2}{2}\right|^1_0=\frac{1}{2}
\end{array}
\]
\section*{Valores esperados y varianzas de funciones lineales de variables aleatorias}

\textbf{5.8) Teorema:} Sean $Y_1,..,Y_n$ y $X_1,...,X_n$ variables aleatorias con $E(Y_i)-\mu_i$ y $E(X_j)=\xi_j$. Se define $U_1=\sum\limits^{n}_{i=1}a_iY_i$ y $U_2=\sum\limits^{m}_{j=1}b_jX_j$ para $a_1,..,a_n,b_1,..,b_m\in\mathbb{R}$. Entonces, 

\begin{enumerate}
	\item $E(U)=\sum\limits^{n}_{i=1} a_iE(Y_i)$
	\item $Var(U_1)=\sum\limits^{n}_{i=1} a_i^2 Var(Y_i)+2\sum\limits^{n}_{1\leq i\leq j \leq n}a_ia_j Cov(Y_iY_j)$
	\begin{itemize}
		\item $Cov(X,Y)=E(x,y)-(E(x))(E(y))$
	\end{itemize}
	\item
	\begin{enumerate}
		\item $Cov(U_1,U_2)= \sum\limits^{n}_{i=1}\sum\limits^{m}_{j=1}a_ia_jCov(Y_iX_j)$
		\item $Cov(X,Y)=(E(x-E(x)))(E(y-E(y)))$
	\end{enumerate}	 
\end{enumerate}
\begin{proof}
\hfill
	\begin{enumerate}
		\item 
		\[
		\begin{array}{rl}
			E(U_1)= &E(\sum^n_i  a_iY_i)=\sum^n_iE(a_iY_i)=(\mathrm{\textit{Por teorema 5.8}})=\\ \\
			&\sum^n_i a_i E(Y_i)=\sum^n_ia_i\mu_i(\leftarrow \textit{Por teorema 5.7})
		\end{array}
		\]
		\item 
		\[
		\begin{array}{rl}
			Var(U_1)=& E((U_1-E(U_1))^2)(\leftarrow \textit{Por def. de varianza})\\ \\
			=& E(\left[\sum^n_ia_iY_i-\sum^n_ia_i\mu_i\right]^2)=E(\left[\sum^n_ia_i(Y_i-\mu_i)\right]^2)\\ \\
			=& E(\sum^n_i\sum^m_j a_i(y_i-\mu_i)a_j(Y_j-\mu_j))\\ \\
			=& E(\sum^n_ia_i^2(Y_i-\mu_i)^2+\underbrace{\sum^n_i\sum^m_j}_{i\neq j}a_ia_j(Y_i-\mu_i)(Y_j-\mu_j))\\ \\
			=& \sum^n_ia_i^2 E((Y_i-\mu_i)^2)+\sum^n_i\sum^m_ja_ia_j E((Y_i-\mu_i)(Y_j-\mu_j))\\ \\
			=&\sum^n_ia_i^2 Var()Y_i)+\sum^n_i\sum^m_j a_ia_j Cov(Y_i,Y_j)\\ \\
			=& \sum^n_ia_i^2 Var(Y_i)+ 2\sum_{1\leq i\leq j\leq n}a_ia_j Cov(Y_i,Y_j)
		\end{array}
		\]
		\item 
		\[
		\begin{array}{rl}
			Cov(U_1,_2)=& E((U_1-E(u_1)))(U_2-E(U_2)))\\ \\
			=& E((\sum^n_ia_iY-i-\sum^n_ia_i\mu_i)(\sum^m_jb_jX_j-\sum^m_jb_j\xi_j))\\ \\
			=& E((\sum^n_i(Y_i-\mu_i)a_i)(\sum^m_jb_j(X_j-\xi_j)))\\ \\
			=& E(\sum^n_i\sum^m_ja_ib_j(Y_i-\mu_i)(X_j-\xi_j))\\ \\
			=&\sum^n_i\sum^m_j a_ib_j E((Y_i-\mu_i)(x_j\xi_j))\\ \\
			=& \sum^n_i\sum^m_j a_ib_j Cov(Y_i,X_j)
		\end{array}
		\]
	\end{enumerate}
\end{proof}
\textbf{\textcolor{red}{5.25 Ej.}}

Sean $Y_1,Y_2,Y_3$ cariables aleatorias, donde $E(Y_1)=1,E(Y_2)=2,E(Y_3)=-1, Var(Y_1)=1,Var(Y_2)=3,Var(Y_3)=5, Cov(Y_1,Y_2)=-0.4,Cov(Y_1,Y_3)=\frac{1}{2}\ y \ Cov(Y_2,Y_3)=2$. Encontrar $E(U)$ y $Var(U)$ donde $U=Y_1-2Y_2+Y_3$.

Si $w=3Y_1+Y_2$, encontrar $Cov(U,W)$

\textbf{Sol.}

\[
\begin{array}{rl}
	E(U)=&E(Y_1-2Y_2+Y_3)=E(Y_1)-2E(Y_2)+E(Y_3)\\ \\
	=& 1-2(2)+(-1)=-4
\end{array}
\]
\par\noindent\rule{\textwidth}{0.5pt}
\[
\begin{array}{rl}
	Var(U)= & Var(Y_1-2Y_2+Y_3)\\ \\
	=&Var(Y_1)+4Var(Y_2)+Var(Y_3)+2[-2Cov(Y_1,Y_2)+Cov(Y_1,Y_3)-2Cov(Y_2,Y_3)]\\ \\
	=& 1+4(3)+5+2[-2(-0.4)+\frac{1}{2}-2(2)]=9.4 
\end{array}
\]
\par\noindent\rule{\textwidth}{0.5pt}
\[
\begin{array}{rl}
	Cov(U,W)=& Var(Y_1-2Y_2+Y_3,3Y_1+Y_2)\\ \\
	=& 3Cov(Y_1,Y_1)+Cov(Y_1,Y_2)-6Cov(Y_2,Y_3)-2 Cov(Y_2,Y_2)+3Cov(Y_3,Y_1)+Cov(Y_3,Y_2)\\ \\
	=& 3Var(Y_1)-0.4-6(-0.4)-2(Var(Y_2))+3(\frac{1}{2})+2\\ \\
	=& 3-0.4-6(-0.4)-2(3)+3(\frac{1}{2})+2=2.5
\end{array}
\]
\textbf{Nota: } Si U y W son variables aleatorias independientes
\[\Rightarrow Cov(U,W)=0\]
Adem'as, $Var(U+W)=Var(U)+Var(W)$

\textbf{\textcolor{red}{6.3} M'etodo de las funciones de distribuci'on}
 
\textbf{Nota: } Si Y tiene una funci'on densidad de probabilidad $f(y)$ y si U es alguna funci'on de Y, entonces 
\[F_U(w)=P([U\leq u])=\underset{\begin{tiny}
R=[(y_1,...,y_n)|U(y_1,...,y_n)\leq u]
\end{tiny}}{\int\int...\int} f(y_1,y_2,...,y_n)dy_1...dy_n\]
\[\Rightarrow f_U(u)=\frac{d}{du}F_U(u)\]

\textbf{\textcolor{red}{6.1 Ej.}}
\[
\begin{array}{rl}
	Y:& \textit{Es una variable aleatoria debido a descomposturas de m'aquinas y otros problemas}
\end{array}
\]
\[f(y)=\left\{
\begin{array}{rl}
	2y,& 0\leq y\leq 1\\
	0, & \textit{en cualquier otro caso}
\end{array}\right.\]
\[U=3Y-1\ \textit{(utilidad diaria, en cientos de \$)}\]
Encontrar la densidad de probabilidad de U
\textbf{Sol.}
\[
\begin{array}{rl}
	F_U(u)=&P(U\leq u) =P(3Y-1\leq u)=P(Y\leq \frac{u+1}{3})\\ 
\end{array}
\]
\[0\leq \frac{u+1}{3}\leq 1\Rightarrow -1\leq u\leq 2\]
\[
\begin{array}{rl}
	\textit{Si } u<-1\Rightarrow \frac{u+1}{3}<0\Rightarrow & F_U(u)=P(Y\leq \frac{u+1}{3}<0)=0\\ \\
	Si u>2\Rightarrow \frac{u+1}{3}>1\Rightarrow &F_U(u)=P(Y\leq \frac{u+1}{3}<1)=1\\ \\
	\textit{Si }-1<u<2\Rightarrow & P(Y\leq \frac{u+1}{3})=\int\limits^{\frac{u+1}{3}}_{-\infty}f(y)dy\\ \\
	=& \int\limits^{\frac{u+1}{3}}_02ydy=
\end{array}
\]



\end{document}



